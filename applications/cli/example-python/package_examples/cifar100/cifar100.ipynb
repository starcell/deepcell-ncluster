{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "\n",
    "\n",
    "import keras\n",
    "import os\n",
    "from keras.datasets.cifar import load_batch\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "dataset_path = '/mnt/input/root/public/cifar-100-python'\n",
    "label_mode = 'fine'\n",
    "if dataset_path and os.path.isdir(dataset_path):\n",
    "    print(f'Loading data from {dataset_path} ...')\n",
    "    fpath = os.path.join(dataset_path, 'train')\n",
    "    x_train, y_train = load_batch(fpath, label_key=label_mode + '_labels')\n",
    "\n",
    "    fpath = os.path.join(dataset_path, 'test')\n",
    "    x_test, y_test = load_batch(fpath, label_key=label_mode + '_labels')\n",
    "\n",
    "    y_train = np.reshape(y_train, (len(y_train), 1))\n",
    "    y_test = np.reshape(y_test, (len(y_test), 1))\n",
    "\n",
    "    if K.image_data_format() == 'channels_last':\n",
    "        x_train = x_train.transpose(0, 2, 3, 1)\n",
    "        x_test = x_test.transpose(0, 2, 3, 1)\n",
    "else:\n",
    "    print('Dataset path not provided or it is pointing to empty directory, downloading dataset ...')\n",
    "    (x_train, y_train), (x_test, y_test) = keras.datasets.cifar100.load_data(label_mode='fine')\n",
    "\n",
    "\n",
    "meta_path = f'{dataset_path}/meta' if dataset_path and os.path.isdir(dataset_path) else \\\n",
    "f\"{Path.home()}/.keras/datasets/cifar-100-python/meta\"\n",
    "\n",
    "with open(meta_path, mode='rb') as meta_file: \n",
    "    label_names = pickle.load(meta_file, encoding='bytes')\n",
    "\n",
    "# Load image labels\n",
    "coarse_labels = [label.decode('utf-8') for label in label_names[b'coarse_label_names']]\n",
    "fine_labels = [label.decode('utf-8') for label in label_names[b'fine_label_names']]\n",
    "\n",
    "print('Dataset loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see how example image looks like\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "image_index = 400  # Change this number to get another image\n",
    "plt.imshow(x_train[image_index])\n",
    "print(fine_labels[y_train[image_index][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_matrix = x_train[image_index].astype('float32')\n",
    "image_matrix /= 255\n",
    "print(image_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of programmatic access to prediction instance\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import requests\n",
    "\n",
    "prediction_instance_url = None # Enter URL from nctl predict launch here\n",
    "auth_header = None  # Enter authorization header content (Bearer ...) from nctl predict launch here\n",
    "\n",
    "if not prediction_instance_url or not auth_header:\n",
    "    raise ValueError('Fill prediction_instance_url and auth_header values.')\n",
    "\n",
    "# Append method verb to prediction instance url\n",
    "prediction_instance_url += ':predict'\n",
    "    \n",
    "# Body contains image which we want to predict\n",
    "body = {\"instances\": [image_matrix.tolist()]}\n",
    "result = requests.post(prediction_instance_url, headers={'Authorization': auth_header}, json=body, verify=False)\n",
    "print(result.text)\n",
    "\n",
    "# Get predicted class\n",
    "prediction_values = json.loads(result.text)['predictions'][0]\n",
    "predicted_class_index = np.argmax(prediction_values)\n",
    "predicted_class = fine_labels[predicted_class_index]\n",
    "print(f'Predicted class: {predicted_class}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
